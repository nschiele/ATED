\section{Semantic Similarity}
\label{sec:semantic-similarity}


\tikzstyle{block} = [rectangle, draw, fill=black!290,
text width=5em, text=white,  text centered, rounded corners, minimum height=4em]
\begin{figure*}
    \centering
    \begin{tikzpicture}[node distance = 2cm, auto]
        % Place nodes
        \node [xshift=-5cm](t1) {$\ATlabel{d}{i}$};
        \node [below of = t1] (t2) {$\ATlabel{e}{j}$};
        \node [block, below right = .5cm and 1cm of t1, yshift=.3cm]  (genbeddings) {\shortstack{Generate\\Semantic\\Embeddings}};
        \node [right of = t1, xshift=4cm]  (et1) {$\vec{e}(\ATlabel{d}{i})$};
        \node [below of = et1]  (et2) {$\vec{e}(\ATlabel{e}{j})$};
        \node [block, right of = genbeddings, xshift= 4.5cm]  (comp) {\shortstack{Vector\\Comparison}};
        \node [right of = comp, xshift = 2cm]  (end) {$\delta(\ATlabel{d}{i}, \ATlabel{e}{j})$};


        % Draw edges
        \draw [->] (t1.east)  -| ($(t1)!0.5!(genbeddings)$) coordinate |-(genbeddings);
        \draw [->] (t2.east)  -| ($(t2)!0.5!(genbeddings)$) coordinate |-(genbeddings);
        \draw [->] (genbeddings.east)  -| ($(genbeddings)!0.5!(et1)$) coordinate |-(et1);
        \draw [->] (genbeddings.east)  -| ($(genbeddings)!0.5!(et2)$) coordinate |-(et2);
        \draw [->] (et1.east)  -| ($(et1)!0.5!(comp)$) coordinate |-(comp);
        \draw [->] (et2.east)  -| ($(et2)!0.5!(comp)$) coordinate |-(comp);
        \draw [->] (comp)  -- (end);
    \end{tikzpicture}
    \caption{Process of calculating the distance between two node labels.}
    \label{fig:semanticreplacement}
\end{figure*}

In most of the tree distance measures described in Section~\ref{sec:related-work}, nodes are only matched, or considered equivalent, if the node labels are identical. Taking one example from our experiment (described in Sections~\ref{sec:methodology}~and~\ref{sec:results}), this would result in the node labels ``Obtain personal data'' and ``obtain personal data'' to not be matched, as these labels are not identical. While other label reconciliation schemes have been proposed, many are based on the string edit distance (Levenshtein distance) of the two node labels. This method is not ideal as it can result in two nodes that are entirely unrelated but with similar vocabulary having small edit distances, while two nodes that are related or identical having large edit distances. In Table~\ref{tab:distances}, we provide a few examples of potential node label comparisons using both normalized Levenshtein distance and semantic similarity. Semantic similarity is calculated using the BERT method and is shown graphically in Figure~\ref{fig:semanticreplacement}. The normalized Levenshtein distance is calculated as one minus the Levenshtein distance divided by the length of the longest string:

\[
\delta\left(\ATlabel{d}{i}, \ATlabel{e}{j}\right) = 1 - \frac{\text{Levenshtein}\left(\ATlabel{d}{i}, \ATlabel{e}{j}\right)}{\max\left(\left|\ATlabel{d}{i}\right|, \left|\ATlabel{e}{j}\right|\right)}
\]

% \[
% \delta(b_i, b_j) = 1 - \frac{\text{Levenshtein}(b_i, b_j)}{\max(|b_i|, |b_j|) }
% \]


In Table~\ref{tab:distances}, can see the extreme example of ``door open'' and ``open door'' which has a Levenshtein distance of 8 (normalized Levenshtein distance of 0), as all letters must be changed. However, the semantic similarity is 0.992, which is the highest of our selected examples. This is because the two labels are near identical in meaning, and the only difference is the order of the words. In contrast, the two labels ``obtain personal data'' and ``obtain personnel'' have a normalized Levenshtein distance of .5882, but a semantic similarity of 0.4507. This is because the two labels are not related, but due to similar language, the normalized string edit distance is relatively small. If we implemented a distance between the two labels
$\delta\left(\ATlabel{d}{i}, \ATlabel{e}{j}\right)$ %$\delta\left(\ATlabel{d}{i}, \ATlabel{e}{j}\right)$ 
to be based on Levenshtein distance, nodes that should incur a cost to edit may not while those that should not incur a cost to edit may.
% This method is not ideal, as it is possible for two unrelated nodes to have small edit distances, such as ``obtain personnel'' and ``obtain personal data'' (edit distance of 7) while related nodes have larger edit distances; such as comparing ``obtain personal data'' and ``gather private info'' (edit distance of 15). In our first example, the two nodes are not related, but due to similar verbiage, the edit distance is relatively small. In the second example, the two nodes have identical meaning, but due to different vocabulary used, the Levenshtein distance between them is significantly larger. If we implemented a distance between the two labels  $\delta\left(\ATlabel{d}{i}, \ATlabel{e}{j}\right)$ to be based on Levenshtein distance, nodes that should incur a cost to edit may not while those that should not incur a cost to edit may.

\begin{table}[]
    \begin{tabular}{@{}llll@{}}
        \toprule
        Label 1              & Label 2             & \begin{tabular}[c]{@{}l@{}}Normalized\\Levenshtein\\ Distance\end{tabular} & \begin{tabular}[c]{@{}l@{}}Semantic \\ Similarity\end{tabular} \\ \midrule
        obtain personal data & obtain personnel    & 0.5882                                                                     & 0.4507                                                         \\
        obtain personal data & gather private info & 0.1176                                                                     & 0.5521                                                         \\
        break open safe      & break open door     & 0.6923                                                                     & 0.7855                                                         \\
        break open safe      & crack safe open     & 0.1538                                                                     & 0.814                                                          \\
        crack safe           & crack door          & 0.5556                                                                     & 0.6692                                                         \\
        door open            & open door           & 0.0                                                                        & 0.992                                                          \\ \bottomrule
    \end{tabular}
\caption{Select examples of potential node label comparisons using both Levenshtein distance and semantic similarity. Semantic similarity is calculated using the methodology shown in Figure~\ref{fig:semanticreplacement}.}
    \label{tab:distances}
\end{table}



What we subsequently would desire is a method of comparing the two labels and making a determination of whether or not nodes are the same based on meaning. If nodes have identical, or relatively identical, meanings, then the cost of replacement should be 0 (\textit{i.e.} matching). If the nodes have dissimilar meanings, then the cost of replacement should be $>0$. We can achieve this by generating semantic embeddings for each node label, and comparing the resulting embeddings. If the semantic similarity is above a given threshold, $\epsilon$, we give the cost of replacement to be 0; otherwise, we give the cost of replacement to be 1. This allows for the Zhang and Shasha algorithm to replace nodes with similar labels at a lower cost than nodes with dissimilar labels.


\subsection{Threshold Problem}
\label{sssec:threshold-problem}

Equivalence is a binary measurement, either labels are equivalent or not. In order to ensure comparability of distance measures, all of the distance measures proposed in the Section~\ref{sec:distance} require a binary determinations of matching (equivalent) or changing (not equivalent). While it may be the case that allowing more nuanced determinations of similarity make result in more nuanced tree distance measures, this would limit our ability to compare the distance measures. By simplifying the distance measures along this metric, we increase our ability to compare the distance measures based on behavior.

However, semantic similarity is a continuous value between 0 and 1, which by its nature is not binary. In order to convert this continuous measure of semantic similarity to one of semantic equivalence, we employ a threshold value of $\epsilon$. Any semantic similarity value above $\epsilon$ is considered equivalent, and any semantic similarity value below $\epsilon$ is considered not equivalent.

Thus, we encounter the threshold problem; the problem of defining a threshold $\epsilon$ for the semantic similarity between two labels. This threshold is necessary to determine if two labels are similar enough to be considered the same. We do not offer a mechanism to account for partial similarity. This could be allowed, but would present a similar problem to the threshold problem; namely, where to set $\epsilon$. We simplify our calculation by not allowing partial calculations, and in Sections~\ref{sec:results}~and~\ref{sec:discussion}, we examine the effect of different $\epsilon$ on the results of our distance calculation.
