\section{Methodology}
\label{sec:methodology}

We apply the validation methodology described in Section~\ref{sec:validation}.


\subsection{Theoretical Validation}
\label{ssec:methodology-examples}


Outside of the real-world experiment we developed to test the attack tree distance measurements, we also examine the distances measures with a series of theoretical examples. For these basic transformation examples (BTEs), we are not concerned with the semantic similarity,  as this is assessed in our experiment. As such, all labels are single capital letters and we set the similar limit ($\epsilon$) to 1, which would require node to be equivalent in order to be matched.

Each of these examples are simple enough that we can intuitively describe a distance. From this, we can examine how each of our distance measures handle each case. If a distance measure differs significantly from what we expect, this is indicative of the measure being deficient in measure some aspect of the distance between attack trees. The examples are shown in Figure~\ref{fig:counterexamples}.


\newcommand{\CEWidth}{.45\linewidth}
\begin{figure}
    \centering
\begin{subfigure}[b]{\linewidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_Base.tex}
        }
        \subcaption{Base Attack Tree}\label{sfig:base}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_OrderReversed.tex}
        }
        \subcaption{Order Reversed}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_RefinementSwitch.tex}
        }
        \subcaption{Refinements Switched}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_ExtraIntermediate.tex}
        }
        \subcaption{Extra Intermediate}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_MissingIntermediate.tex}
        }
        \subcaption{Missing Intermediate}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2.5cm}{!}{
            \input{content/snippets/CE/CE_ExtraLeaf.tex}
        }
        \subcaption{Extra Leaf}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_MissingLeaf.tex}
        }
        \subcaption{MissingLeaf}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_ChangedRoot.tex}
        }
        \subcaption{Changed Root}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_ChangedIntermediate.tex}
        }
        \subcaption{Changed Intermediate}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_ChangedLeaf.tex}
        }
        \subcaption{Changed Leaf}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_MoveAdjacent.tex}
        }
        \subcaption{Move Adjacent}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{2cm}{!}{
            \input{content/snippets/CE/CE_MoveUp.tex}
        }
        \subcaption{Move Up}\label{fig:b}
    \end{subfigure}
\begin{subfigure}[b]{\CEWidth}
        \centering
        \resizebox{1.8cm}{!}{
            \input{content/snippets/CE/CE_MoveDown.tex}
        }
        \subcaption{Move Down}\label{fig:b}
    \end{subfigure}
\caption{Basic Transformation Examples (BTEs)}\label{fig:counterexamples}
\end{figure}





\subsection{Experimental Validation}

\subsubsection{Experimental Study Design}
\label{ssec:method-study-design}

Students were assigned a project related to attack defense trees as a part of their regular coursework. The project was a mandatory, graded assignment. Students had the option to provide consent for their anonymized responses to be collected for research purposes, this is described in detail in Section~\ref{ssec:ethics}. The assignment consisted of four components. In each component, students were required to create an attack (defense) tree (ADT) using a web application of our own design. Of the four components, the third was included in the assignment for the purposes of validating our approach. The text of the entire study is included in Appendix~\ref{app:exp-questions}; however, we only expound upon the relevant section in this work.

The third component of the study contains two parts. In part A, students were tasked with creating an AT from a provided, written, scenario. The scenario was adapted from an attack tree shown in Naik~\etal~\cite{naikEvaluationPotentialAttack2022}. The scenario was as follows:

\texttt{Many attackers aim to obtain personal data. Gathering personal data can be completed through unauthorized access to profile, credential creep, or a background data attack. Unauthorized access to profile requires gaining user credentials and accessing the profile. The credentials can be gained through a malware attack or a social engineering attack, and the profile can be accessed by stealing a phone or by remote access. Credential creep can be completed by submitting a request for additional data other than what is needed for verification or by user profiling. Finally, a background data attack requires both obtaining a sensitive dataset and linking the dataset via a request for verification.}

This description was created by reading the attack tree in Naik~\etal\ abstraction level by abstraction level, always going from left to right~\cite{naikEvaluationPotentialAttack2022}. The intention of Part A was to assess the requirements of unfiltered labels as well as processing the structure of the attack tree, as the underlying information in the attack trees should be identical between students. As the trees were effectively the same tree, distance between them would more likely be due to an artifact of the distance measure as opposed to the actual distance present in the data. By examining this, we would be able to validate our approach.

We then asked students in part B to expand upon their attack tree by ``doing your own research, add at least 5 new nodes and 2 new refinements to the attack tree you created in the previous section''. In all, this creates a relatively predictable, yet varied, dataset. In Part A, all trees should roughly be the same, baring minor changes in the label of nodes or the order of nodes. We expect that any large differences in part A to be due to misunderstanding the assignment or misreading the scenario. As Part B is built from each students' part A, we expect that the ``core'' of their attack tree to remain unchanged but the added nodes and refinement should introduce an ability to evaluate edit distance. Based on previous experience with similar studies, we expect most students to add exactly 5 new nodes and 2 new refinements, which should allows for some predictable edit distance (namely, the cost of adding 5 new nodes). This allows us to evaluate the distance measures as a metric, as well as further validation. As each student produced two trees, a base and an extension, by comparing them we can validate the distance measures. As if the distance measures are not able to recognize the base tree, the distance measure may not be suitable.

\subsubsection{Analysis}
\label{ssec:method-analysis}
From the first task (AT1), we would expect all trees to be roughly equal. There may be some variation due to missing or added information, from participants who may have deviated from the instructions. We would expect for the average distance of all AT1 trees to remain the same for increasing values of $\epsilon$. From this, we can establish ideal values of $\epsilon$, as once the average distance starts increasing, values that were previously equivalent and likely should be equivalent will start to rise. We can further validate by comparing AT1 to AT2 per participant, as these graphs should be constant for any value of $\epsilon$, as the only difference should be added nodes and added nodes are unaffected by the semantic similarity limit (as added nodes will always have a distance of 1). If the distance measures comparing AT1 to AT2 are not constant for all values of $\epsilon$, this would indicate a distance measure that behaves in an unexpected and potentially invalid manner. Finally, by comparing the difference distance measures on AT2, which are truly different attack trees, we can see if the distance measures behave similarly. Ideally, distance measures incorporate all aspects of attack trees, so their behavior should be similar. If the distance measures do not behave similarly, it may be a sign of an invalid distance measure. Our code for all distance algorithms and analysis is provided here: \url{https://anonymous.4open.science/r/ATD-FB1F/README.md}.

\paragraph{Web Application}

For this assignment, we created a web application which can be used to create attack defense trees. The web application contains a graphic interface with which users can add, delete and modify nodes~\cite{mohalaiaImplementingUserInterface2023}. Additionally, the web application contains an SQL-like language that can be used to generate ADTs~\cite{mezaADTLangDeclarativeLanguage2023}. The Web application additionally allows users to download ADTs as images as well as in the ADTool XML schema as defined by Kordy~\etal~\cite{kordy_adtool_2013}. The web application can be found here: \url{https://anonymous.4open.science/w/ADT-Web-App-AB3C/}.

\subsubsection{Participants}
The participants in this study were all third year bachelor students taking part in a minor on cyber security and governance. Most students were in policy related majors such as Security Studies or International Relations. The participants on average had only a few months of programming experience, which was a result of another course in the minor. Students were asked if they had any prior knowledge of threat models or attack trees, and only a few students had any prior knowledge. Students took this course in the fall semester of 2023. As shown by Naiakshina~\etal\ and Karpati~\etal, in the context of cyber security, students are a sufficient proxy for practitioners~\cite{karpatiComparingAttackTrees2014, naiakshinaConductingSecurityDeveloper2020}.



% \subsubsection{Processing}

% The attack tree data was collected in the form of XML data. This data was then processed using a Python script. The script was used to extract the attack trees from the XML data and to convert the attack trees into a format that could be used by our implementation of the Zhang and Shasha algorithm. We started with the pre-implemented and tested \texttt{zss} library from Tim Henderson~\cite{hendersonZssTreeEdit}. We then modified the library to include our semantic label replacement cost and refinement change cost to create an implementation of the Zhang and Shasha algorithm that should be effective for attack trees. We subsequently used this implementation to calculate the tree edit distance between the attacks trees.  

% Our code for all distance algorithms is provided here: \url{https://anonymous.4open.science/r/ATD-FB1F/README.md}.


\subsubsection{Sentence Embeddings}
\label{ssec:method-embeddings}

As we discussed in Section~\ref{sec:semantic-similarity}, BERT is a state-of-the-art method for creating sentence embeddings. We use the \texttt{SentenceTransformers} library to calculate the sentence embeddings and cosine similarity to calculate embedding vector difference. As stated previously, our contribution is not the creation of these embeddings; additionally, our use of sentence embeddings is method agnostic, and any method for generating sentence or word embeddings could be used with our methodology. We used multiple different pre-trained BERT models and aggregated the results to illustrate that any results we found were not the result of the use of a specific model. Additionally, we did not fine tune any model. We used the following models: \texttt{paraphrase-multilingual-MiniLM-L12}, \texttt{all-mpnet-base}, and \texttt{all-MiniLM-L12}.

\subsubsection{Ethics}
\label{ssec:ethics}
This study was approved by the the Ethics Review Board at a european university\anonfoot. Students were informed of study and were requested to give consent for their responses to be included in the study. Multiple safeguards were used to ensure that students did not feel pressured into giving consent, as the assignment was a mandatory course component. Students were informed that they could withdraw their consent at any time, and that their responses would be anonymized. 






