\section{Semantic Label Replacement}

In tree edit distance, the replacement calculation is made when the root nodes of subtrees are not the same~\cite{zhang_simple_1989}. 


\tikzstyle{block} = [rectangle, draw, fill=black!290, 
text width=5em, text=white,  text centered, rounded corners, minimum height=4em]

    
\begin{figure*}
\begin{tikzpicture}[node distance = 2cm, auto]
    % Place nodes
    \node [xshift=-5cm](t1) {$T_1[i].\text{label}$};
    \node [below of = t1] (t2) {$T_2[j].\text{label}$};
    \node [block, below right = .5cm and 1cm of t1, yshift=.3cm]  (genbeddings) {\shortstack{Generate\\Semantic\\Embeddings}};
    \node [right of = t1, xshift=4cm]  (et1) {$\vec{e}(T_1[i].\text{label})$};
    \node [below of = et1]  (et2) {$\vec{e}(T_2[j].\text{label})$};
    \node [block, right of = genbeddings, xshift= 4.5cm]  (comp) {\shortstack{Vector\\Comparison}};
    \node [right of = comp, xshift = 2cm]  (end) {$\delta(T_1[i].\text{label}, T_2[j].\text{label})$};


    % Draw edges
    \draw [->] (t1.east)  -| ($(t1)!0.5!(genbeddings)$) coordinate |-(genbeddings);
    \draw [->] (t2.east)  -| ($(t2)!0.5!(genbeddings)$) coordinate |-(genbeddings);
    \draw [->] (genbeddings.east)  -| ($(genbeddings)!0.5!(et1)$) coordinate |-(et1);
    \draw [->] (genbeddings.east)  -| ($(genbeddings)!0.5!(et2)$) coordinate |-(et2);
    \draw [->] (et1.east)  -| ($(et1)!0.5!(comp)$) coordinate |-(comp);
    \draw [->] (et2.east)  -| ($(et2)!0.5!(comp)$) coordinate |-(comp);
    \draw [->] (comp)  -- (end);
\end{tikzpicture}
\caption{Process of calculating the distance between two node labels.}
\label{fig:semanticreplacement}
\end{figure*}




% One approach would be to ignore labels entirely and attempt to perform a tree edit comparison purely based on the structure of attack trees. This would be akin to setting the cost of replacement to 0. However, there is an additional issue as the Zhang and Shasha algorim relies on an initial mapping of like nodes between the two trees, a mapping done primarily based on labels. In order to ignore labels and define an edit distance based on tree structure alone, we would need to perform such a mapping based on the placement of nodes within the tree. Such a mapping would be possible

% , and would .  While this may yield interesting results, it can result in two trees being evaluated with an edit distance of 0 while not at all being similar (as they are structurally the same). A small example is provided in Figure~\NS{Add fig} where the two trees are structurally equivalent, and all that is needed to edit one tree to another would be to replace all nodes. If the cost of replacement is 0, then the edit distance between the two trees is likewise 0. 




\subsection{Semantic similarity}
\label{ssec:semantic-similarity}

\NS{should this be in background? This feels backgroundy}

Comparing two natural language sentences is a widely explored area of research. Our work does not further the state of the art of semantic comparison, rather, we apply the state of the art in a novel manner. Natural Language Inference (NLI) is a subproblem within Natural Language Processing (NLP) in which the relationship between two sentences is given. A common model used in NLI tasks is Bidirectional Encoder Representations from Transformers (BERT), in which a masked language model (MLM) is used to create pre-trained word embeddings. The Bidirectional nature of BERT allows for the model to understand the context of a word based on the words around it. This is in contrast to previous models such as Word2Vec, which only consider the context of a word in one direction or do not consider the larger context of sentences and only comparing word embeddings. BERT has been shown to be highly effective in NLI tasks~\cite{devlin_bert_2019}. We use BERT to generate sentenceembeddings for the labels of nodes in attack trees. We then compare these embeddings using cosine similarity. 







% After performing this mapping step, we compute tree edit distance as described by Zhang and Shasha. However, the cost of replacing a node with another node is given as 1 - semantic similarity. In this way, nodes that have highly similar labels (a semantic similarity approaching 1) will have a low replacement cost, while those with little to no semantic similarity will have high replacement cost. Additionally, if we give that the cost of adding or removing a node to be 1, we prime the Zhang and Shasha algorithm to attempt to replace as many nodes as possible. \NS{this may not be a good thing}

\subsection{Semantic replacement}
\label{ssec:semantic-repalcement}

In the original Zhang and Shasha algorithm, nodes are only matched (``replaced'' with no cost) if the node labels are identical. In the examples we provide in Section~\ref{sec:results}, this would result in the node labels ``Obtain personal data'' and ``obtain personal data'' to not be matched, as these labels are not identical. While other label reconciliation schemes have been proposed, many are based on the string edit distance (Levenshtein distance) of the two node labels. This method is not ideal as it can result in two nodes that are entirely unrelated but with similar vocabulary having small edit distances, while two nodes that are related or identical having large edit distances. In Table~\ref{tab:distances}, we provide a few examples of potential node label comparisons using both normalized Levenshtein distance and semantic similarity. Semantic similarity is calculated using the methodology described in Section~\ref{sec:results}. The normalized Levenshtein distance is calculated as one minus the Levenshtein distance divided by the length of the longest string:

\[
    \delta_L\left(T_1[i].\text{label}, T_2[j].\text{label}\right) = 1 - \frac{\text{Levenshtein}\left(T_1[i].\text{label}, T_2[j].\text{label}\right)}{\max\left(\left|T_1[i].\text{label}\right|, \left|T_2[j].\text{label}\right|\right)}
    \]

We can see the extreme example of ``door open'' and ``open door'' which has a Levenshtein distance of 8 (normalized Levenshtein distance of 0), as all letters must be changed. However, the semantic similarity is 0.992, which is the highest of our selected examples. This is because the two labels are near identical in meaning, and the only difference is the order of the words. In contrast, the two labels ``obtain personal data'' and ``obtain personnel'' have a normalized Levenshtein distance of .5882, but a semantic similarity of 0.4507. This is because the two labels are not related, but due to similar verbiage, the normalized string edit distance is relatively small. If we implemented a distance between the two labels  $\delta\left(T_1[i].\text{label}, T_2[j].\text{label}\right)$ to be based on Levenshtein distance, nodes that should incur a cost to edit may not while those that should not incur a cost to edit may.
% This method is not ideal, as it is possible for two unrelated nodes to have small edit distances, such as ``obtain personnel'' and ``obtain personal data'' (edit distance of 7) while related nodes have larger edit distances; such as comparing ``obtain personal data'' and ``gather private info'' (edit distance of 15). In our first example, the two nodes are not related, but due to similar verbiage, the edit distance is relatively small. In the second example, the two nodes have identical meaning, but due to different vocabulary used, the Levenshtein distance between them is significantly larger. If we implemented a distance between the two labels  $\delta\left(T_1[i].\text{label}, T_2[j].\text{label}\right)$ to be based on Levenshtein distance, nodes that should incur a cost to edit may not while those that should not incur a cost to edit may.

\begin{table}[]
    \begin{tabular}{@{}llll@{}}
        \toprule
Label 1              & Label 2             & \begin{tabular}[c]{@{}l@{}}Normalized\\Levenshtein\\ Distance\end{tabular} & \begin{tabular}[c]{@{}l@{}}Semantic \\ Similarity\end{tabular} \\ \midrule
obtain personal data & obtain personnel    & 0.5882                                                             & 0.4507                                                         \\
obtain personal data & gather private info & 0.1176                                                             & 0.5521                                                         \\
break open safe      & break open door     & 0.6923                                                              & 0.7855                                                         \\
break open safe      & crack safe open     & 0.1538                                                             & 0.814                                                          \\
crack safe           & crack door          & 0.5556                                                              & 0.6692                                                         \\
door open            & open door           & 0.0                                                             & 0.992                                                          \\ \bottomrule
    \end{tabular}
    \caption{Select examples of potential node label comparisons using both Levenshtein distance and semantic similarity. Semantic similarity is calculated using the methodology described in Section~\ref{sec:results}}
    \label{tab:distances}
\end{table}


What we subsequently would desire is a method of comparing the two labels and making a determination of whether or not nodes are the same based on meaning. If nodes have identical, or relatively identical, meanings, then the cost of replacement should be 0 (\textit{i.e.} matching). If the nodes have dissimilar meanings, then the cost of replacement should be $>0$. We can achieve this by generating semantic embeddings for each node label, and comparing the resulting embeddings. If the semantic similarity is above a given threshold, $\epsilon$, we give the cost of replacement to be 0; otherwise, we give the cost of replacement to be 1. This allows for the Zhang and Shasha algorithm to replace nodes with similar labels at a lower cost than nodes with dissimilar labels.

% The second use of semantic similarity is in the Zhang and Shasha replacement operation. In the provided algorithm, a label is comparison is made between the root nodes of two trees when calculating the cost of replacements. If the root node labels are the same, the cost of replacement is given as 0; otherwise the cost is given as 1. We adjust this label comparison by applying a semantic distance comparison.

% We calculate the semantic embeddings for each node label, and compare the result embeddings. If the semantic similarity is above a given threshold, $\epsilon$, we give the cost of replacement to be 0; otherwise, we give the cost of replacement to be 1. This allows for the Zhang and Shasha algorithm to replace nodes with similar labels at a lower cost than nodes with dissimilar labels.


\begin{lemma}
    $\gamma\left(T_1[i].\text{label} \rightarrow T_2[j].\text{label}\right) \le \gamma(T_2[j] \rightarrow {\Lambda}) + \gamma(\Lambda \rightarrow {T_2[j]})$

    \begin{proof}
        We refer to the proof in Lemma~\ref{lem:gamma-delta-2}. 
        
        If we assume $\gamma\left(T_1[i].\text{label} \rightarrow T_2[j].\text{label}\right) > \gamma(T_2[j] \rightarrow {\Lambda}) + \gamma(\Lambda \rightarrow {T_2[j]})$, we arrive at the same conclusion that it is not possible to have an optimal edit sequence with a change node operation. As such, either $\gamma\left(T_1[i].\text{label} \rightarrow T_2[j].\text{label}\right) \le \gamma(T_2[j] \rightarrow {\Lambda}) + \gamma(\Lambda \rightarrow {T_2[j]})$ or edit sequences can only consist of removal and a
    \end{proof}
\end{lemma}



When we examine the forest distance equation from Zhang and Shasha~\cite{zhang_simple_1989}, we see the cost of replacing a given node as
% \begin{equation*}
\begin{align*}
    \text { forestdist } & \left(l\left(i_1\right) . . l(i)-1, l\left(j_1\right) . . l(j)-1\right) \\
                         & + \text { forestdist }(l(i) \ldots i-1, l(j) . . j-1)                   \\
                         & + \gamma\left(T_1[i] \rightarrow T_2[j]\right)
\end{align*}
% \end{equation*}


We previously defined $\gamma\left(T_1[i] \rightarrow T_2[j]\right)$  as the sum $\gamma({T_1[i].\text{label}} \rightarrow {T_2[j].\text{label}}) + \gamma(\Delta)$. We now define $\gamma\left(T_1[i].\text{label} \rightarrow T_2[j].\text{label}\right)$ to be the following:

\begin{multline*}
    \gamma\left(T_1[i].\text{label} \rightarrow T_2[j].\text{label}\right)=\\\left\{\begin{array}{ll}
        0, & \text { if } \delta\left(T_1[i].\text{label}, T_2[j].\text{label}\right)>\epsilon \\
        1, & \text { otherwise }
    \end{array}\right.
\end{multline*}

And from this we give $\delta\left(T_1[i].\text{label}, T_2[j].\text{label}\right)$ to be the semantic similarity between the two node labels. We calculate the semantic similarity by generating semantic embeddings for each node label, and comparing the resulting embeddings. If the semantic similarity is above a given threshold, $\epsilon$, we give the cost of replacement to be 0; otherwise, we give the cost of replacement to be 1. This allows for the Zhang and Shasha algorithm to replace nodes with similar labels at a lower cost than nodes with dissimilar labels. The manner in which these embeddings are created and the comparison of the resulting embedding vectors is not a contribution of this work, and ultimately our work is agnostic to the method used. Our contribution is the application of these methods to tree edit distance in the context of cyber security, not the methods themselves. his method allows for a more nuanced edit comparison to take place. 




% \begin{equation*}
%     \text { forestdist }\left(l\left(i_1\right) \ldots i, l\left(j_1\right) . . j\right)=\min \left\{\begin{array}{l}
%         \text { forestdist }\left(l\left(i_1\right) \ldots i-1, l\left(j_1\right) . . j\right)+\gamma\left(T_1[i] \rightarrow \Lambda\right), \\
%         \text { forestdist }\left(l\left(i_1\right) . . i, l\left(j_1\right) . . j-1\right)+\gamma\left(\Lambda \rightarrow T_2[j]\right),    \\
%         \text { forestdist }\left(l\left(i_1\right) . . l(i)-1, l\left(j_1\right) . . l(j)-1\right)                                           \\
%         + \text { forestdist }(l(i) \ldots i-1, l(j) . . j-1)                                                                                 \\
%         +\gamma\left(T_1[i] \rightarrow T_2[j]\right) .
%     \end{array}\right.
% \end{equation*}

Selecting the $\epsilon$ value will ultimately depend on the context in which this comparison is used.If $\epsilon$ is too lowe, then the cost of replacemenst will be 0 for all nodes, and the tree edit distance will be purely based on the structure of the trees as all replacement operations will have no cost. If $\epsilon$ is too high, then the cost of replacement will be 1 for all nodes, and the tree edit distance will be identical to the original Zhang and Shasha algorithm (with all replacement operations having a cost of 1). In Figure~\ref{img:similaritylimits}, we show the average distance between the 38 experimental ATs per semantic similarity limit. We see that as the semantic similarity limit increases, the average distance between the trees increases, as the cost of all replacement operations slowly move from cost 0 toward cost 1. We discuss this further in Section~\ref{sec:results}